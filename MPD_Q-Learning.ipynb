{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4560b9-4850-4494-8cd6-263df484957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\minhn\\lib\\site-packages (1.24.3)\n",
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     ---------------------------------------- 0.0/721.7 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/721.7 kB ? eta -:--:--\n",
      "      --------------------------------------- 10.2/721.7 kB ? eta -:--:--\n",
      "     ---- -------------------------------- 92.2/721.7 kB 581.0 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 122.9/721.7 kB 654.9 kB/s eta 0:00:01\n",
      "     ------- ---------------------------- 143.4/721.7 kB 607.9 kB/s eta 0:00:01\n",
      "     -------- --------------------------- 174.1/721.7 kB 615.9 kB/s eta 0:00:01\n",
      "     ---------- ------------------------- 204.8/721.7 kB 621.6 kB/s eta 0:00:01\n",
      "     ----------- ------------------------ 235.5/721.7 kB 600.7 kB/s eta 0:00:01\n",
      "     ------------- ---------------------- 276.5/721.7 kB 655.8 kB/s eta 0:00:01\n",
      "     --------------- -------------------- 317.4/721.7 kB 655.0 kB/s eta 0:00:01\n",
      "     ----------------- ------------------ 358.4/721.7 kB 696.3 kB/s eta 0:00:01\n",
      "     ------------------- ---------------- 389.1/721.7 kB 692.6 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 440.3/721.7 kB 724.0 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 501.8/721.7 kB 749.3 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 553.0/721.7 kB 788.8 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 604.2/721.7 kB 809.2 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 645.1/721.7 kB 812.9 kB/s eta 0:00:01\n",
      "     ---------------------------------- - 696.3/721.7 kB 828.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 721.7/721.7 kB 828.2 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in d:\\minhn\\lib\\site-packages (from gym) (1.24.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in d:\\minhn\\lib\\site-packages (from gym) (2.2.1)\n",
      "Collecting gym-notices>=0.0.4 (from gym)\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827631 sha256=e1bddf4dd4030fae29ba23c41716c59b736d02b04a4d0e428ff738154003c23e\n",
      "  Stored in directory: c:\\users\\minhn\\appdata\\local\\pip\\cache\\wheels\\1c\\77\\9e\\9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e3dc56c-d49e-49b4-951b-ed331b6a119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from gym.envs.registration import register\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b583f55b-38e6-4718-b49a-6082d7d03e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Discrete(16)\n",
      "Action space: Discrete(4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gym.spaces.discrete.Discrete"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Register evironment\n",
    "try:\n",
    "    register(\n",
    "        id='FrozenLakeNoSlip-v0',\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name' : '4x4', 'is_slippery':False},\n",
    "        max_episode_steps=100,\n",
    "        reward_threshold=0.78, \n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env_name = \"FrozenLakeNoSlip-v0\"\n",
    "# Create environment\n",
    "env = gym.make(env_name)\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "type(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fa4cf1-f050-40af-b94b-1501d31772f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "class Agent():\n",
    "    def __init__(self, env):\n",
    "        self.action_size = env.action_space.n\n",
    "        print(\"Action size:\", self.action_size)\n",
    "\n",
    "    # get random action\n",
    "    def get_action(self, state):\n",
    "        action = random.choice(range(self.action_size))\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269012c6-39ab-420d-ad23-377dd14bda43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action size: 4\n",
      "State size: 16\n"
     ]
    }
   ],
   "source": [
    "# Agent Q-learning\n",
    "class QL_Agent(Agent):\n",
    "    def __init__(self, env, discount_rate=0.97, learning_rate=0.01):\n",
    "        super().__init__(env)\n",
    "        self.state_size = env.observation_space.n\n",
    "        print(\"State size:\", self.state_size)\n",
    "        self.eps = 1.0\n",
    "        self.discount_rate = discount_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_Q_table()\n",
    "        \n",
    "    def init_Q_table(self):\n",
    "        self.q_table = 1e-4*np.random.random([self.state_size, self.action_size])\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        q_state = self.q_table[state]\n",
    "        action_greedy = np.argmax(q_state)\n",
    "        action_random = super().get_action(state)\n",
    "        # choose between greedy and random actions base on epsilon\n",
    "        return action_random if random.random() < self.eps else action_greedy\n",
    "    \n",
    "    def train(self, experience):\n",
    "        state, action, next_state, reward, done = experience\n",
    "        \n",
    "        q_next = self.q_table[next_state]\n",
    "        q_next = np.zeros([self.action_size]) if done else q_next\n",
    "        q_target = reward + self.discount_rate * np.max(q_next)\n",
    "        \n",
    "        q_update = q_target - self.q_table[state,action]\n",
    "        # update Q-value\n",
    "        self.q_table[state,action] += self.learning_rate * q_update\n",
    "        \n",
    "        if done:\n",
    "            #update epsilon\n",
    "            self.eps = self.eps * 0.99\n",
    "        \n",
    "agent = QL_Agent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81cf06a-ca5f-43d9-810d-851ea261fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state: 15 action: 2\n",
      "Epi: 599, Total reward: 600.0, eps: 5.784069691292563e-06\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "[[5.15658150e-05 5.15465936e-05 5.10592147e-01 5.15508010e-05]\n",
      " [5.22086823e-05 5.11224445e-05 6.62569539e-01 5.22046788e-05]\n",
      " [5.25093650e-05 7.94972729e-01 5.24980331e-05 5.16834404e-05]\n",
      " [5.25528620e-05 5.53758907e-06 4.67136468e-05 4.50667890e-05]\n",
      " [5.14719450e-05 5.03645460e-05 4.52841769e-06 2.82080445e-04]\n",
      " [5.69536075e-05 1.11663522e-05 2.47261473e-05 5.14765236e-05]\n",
      " [3.00038727e-05 8.93012150e-01 5.08411092e-05 5.20720670e-05]\n",
      " [7.14208256e-05 4.74147695e-05 1.81176496e-05 7.04379104e-06]\n",
      " [6.21222639e-05 4.27941806e-05 6.25375317e-05 6.63711866e-05]\n",
      " [1.45230152e-05 4.10699254e-05 4.31795411e-05 4.07701579e-05]\n",
      " [6.24889222e-05 9.56730836e-01 3.59510122e-05 6.26212985e-05]\n",
      " [2.30306483e-05 8.26036591e-05 6.50437685e-05 3.86002757e-05]\n",
      " [6.64501378e-05 4.56855793e-05 3.39967502e-05 6.09526957e-05]\n",
      " [2.73572671e-05 2.75624322e-05 9.30193097e-06 3.99285435e-05]\n",
      " [6.64798350e-05 6.66124341e-05 9.98129453e-01 6.66222293e-05]\n",
      " [9.35182660e-05 3.74448613e-05 9.97140515e-05 9.33759294e-05]]\n"
     ]
    }
   ],
   "source": [
    "total_reward = 0\n",
    "for i in range(600):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.get_action(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        agent.train((state,action,next_state,reward,done))\n",
    "\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        print(\"state:\", state, \"action:\", action)\n",
    "        print(f\"Epi: {i}, Total reward: {total_reward}, eps: {agent.eps}\")\n",
    "        # Render the current state of the environment\n",
    "        env.render()\n",
    "        print(agent.q_table)\n",
    "        #pause for a short duration\n",
    "        time.sleep(0.0005)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144feaae-4a8a-45c8-87f1-a4a032a76735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
